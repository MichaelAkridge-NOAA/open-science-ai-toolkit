{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "unzipped_folder = r\"V:\\temp\\_yolo_train\\mouss_source_data\"  # Use raw string for Windows paths\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is properly set up\n",
    "print(torch.version.cuda)  # Prints the version of CUDA PyTorch is using\n",
    "print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "print(f\"GPU Name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "\n",
    "# Step 3: Check if CUDA is available and load the large model (YOLOv8x) to CUDA if possible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 4: Create folders for the new dataset (images and labels)\n",
    "base_path = r\"V:\\temp\\20240923_yolo_train\\lgrds_fish_dataset\"\n",
    "\n",
    "# Step 11: Train the YOLOv8n model using the generated dataset\n",
    "small_model = YOLO(\"yolov8n.pt\")  # Load the smaller YOLOv8n model\n",
    "\n",
    "# Train the model using the generated fish-only dataset\n",
    "small_model.train(data=yaml_file_path, epochs=50, imgsz=416, batch=16, lr0=0.001)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "# Save the model\n",
    "small_model.save(r\"V:\\temp\\20240923_yolo_train\\yolov8n_fish_trained_lgrds.pt\")\n",
    "\n",
    "# Evaluate model performance\n",
    "metrics = small_model.val(data=yaml_file_path)  # Evaluate precision, recall, and mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "unzipped_folder = r\"V:\\temp\\20161014_192048_1\"  # Use raw string for Windows paths\n",
    "\n",
    "# Step 3: Check if CUDA is available and load the large model (YOLOv8x) to CUDA if possible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the large model (YOLOv8x) that was fine-tuned for VME detection\n",
    "large_model = YOLO(r\"V:\\temp\\models\\best.pt\")  # Update to your model path\n",
    "large_model = large_model.to(device)  # Move the model to GPU (CUDA) if available\n",
    "\n",
    "# Step 4: Create folders for the new dataset (images and labels)\n",
    "base_path = r\"V:\\temp\\lg_fish_dataset\"\n",
    "\n",
    "\n",
    "# Step 10: Create a YAML file for the dataset\n",
    "fish_dataset_yaml = f\"\"\"\n",
    "train: \"V:/temp/lg_fish_dataset/images/train\"\n",
    "val: \"V:/temp/lg_fish_dataset/images/val\"\n",
    "\n",
    "# Number of classes\n",
    "nc: 1\n",
    "\n",
    "# Class names\n",
    "names: ['Fish']\n",
    "\"\"\"\n",
    "\n",
    "# Save the YAML file\n",
    "yaml_file_path = os.path.join(base_path, \"fish_dataset.yaml\")\n",
    "with open(yaml_file_path, \"w\") as yaml_file:\n",
    "    yaml_file.write(fish_dataset_yaml)\n",
    "\n",
    "print(f\"YAML file created: {yaml_file_path}\")\n",
    "\n",
    "\n",
    "# Step 11: Train the YOLOv8n model using the generated dataset\n",
    "small_model = YOLO(\"yolov8n.pt\")  # Load the smaller YOLOv8n model\n",
    "\n",
    "# Train the model using the generated fish-only dataset\n",
    "small_model.train(data=yaml_file_path, epochs=50, imgsz=416, batch=16, lr0=0.001)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "# Save the model\n",
    "small_model.save(r\"V:\\temp\\yolov8n_fish_trained_lgds.pt\")\n",
    "\n",
    "# Evaluate model performance\n",
    "metrics = small_model.val(data=yaml_file_path)  # Evaluate precision, recall, and mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg41uZvaZ3wO"
   },
   "source": [
    "# Yolo8n Training -\n",
    "## Unsupervised training of Yolo8n (nano) model with Yolo8x large model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJ5DnFdF6QdY",
    "outputId": "e2acb820-af35-40bd-8144-1fc709f8726d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import py7zr\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#!pip install ultralytics\n",
    "#!pip install py7zr  # Make sure py7zr is installed for extracting .7z files\n",
    "\n",
    "# Step 2: Unzip the original images from the .7z archive\n",
    "# Define the path to the .7z file containing the images\n",
    "seven_zip_file_path = \"/content/original.7z\"  # Replace with your .7z file path\n",
    "unzipped_folder = \"/content\"\n",
    "\n",
    "# Extract the .7z file into the specified directory\n",
    "with py7zr.SevenZipFile(seven_zip_file_path, mode='r') as archive:\n",
    "    archive.extractall(unzipped_folder)\n",
    "\n",
    "unzipped_folder = \"/content/original/original\"\n",
    "\n",
    "# Step 3: Check if CUDA is available and load the large model (YOLOv8x) to CUDA if possible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the large model (YOLOv8x) that was fine-tuned for VME detection\n",
    "large_model = YOLO(\"/content/best.pt\")  # Replace with your model path\n",
    "large_model = large_model.to(device)  # Move the model to GPU (CUDA) if available\n",
    "\n",
    "# Step 4: Create folders for the new dataset (images and labels)\n",
    "base_path = \"/content/fish_dataset\"\n",
    "\n",
    "# Create directories for train/val images and labels\n",
    "os.makedirs(f\"{base_path}/images/train\", exist_ok=True)\n",
    "os.makedirs(f\"{base_path}/images/val\", exist_ok=True)\n",
    "os.makedirs(f\"{base_path}/labels/train\", exist_ok=True)\n",
    "os.makedirs(f\"{base_path}/labels/val\", exist_ok=True)\n",
    "\n",
    "# Step 5: Define the input folder containing the original images (unzipped)\n",
    "input_images_folder = unzipped_folder\n",
    "image_paths = [os.path.join(input_images_folder, img) for img in os.listdir(input_images_folder) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Split images into train and validation (80% train, 20% validation)\n",
    "train_images = image_paths[:int(0.8 * len(image_paths))]\n",
    "val_images = image_paths[int(0.8 * len(image_paths)):]\n",
    "\n",
    "# Function to save YOLO format labels (class_id x_center y_center width height)\n",
    "def save_yolo_labels(label_path, class_id, bbox, image_width, image_height):\n",
    "    if bbox is not None and len(bbox) > 0:  # Ensure there are bounding boxes\n",
    "        x_center = (bbox[0] + bbox[2]) / 2 / image_width\n",
    "        y_center = (bbox[1] + bbox[3]) / 2 / image_height\n",
    "        width = (bbox[2] - bbox[0]) / image_width\n",
    "        height = (bbox[3] - bbox[1]) / image_height\n",
    "        with open(label_path, \"a\") as f:\n",
    "            f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "        print(f\"Label saved for {label_path}: {class_id} {x_center} {y_center} {width} {height}\")\n",
    "    else:\n",
    "        print(f\"No bounding boxes found for {label_path}, skipping label.\")\n",
    "\n",
    "# Function to process images, run inference, and save results\n",
    "def process_images(image_paths, split):\n",
    "    for image_path in image_paths:\n",
    "        # Step 6: Run the large model to detect objects in the image (with GPU if available)\n",
    "        results = large_model(image_path)\n",
    "\n",
    "        # Check if any instances were detected\n",
    "        print(f\"Processing {image_path}, found {len(results[0].boxes)} instances.\")\n",
    "\n",
    "        # Extract image dimensions\n",
    "        img_name = os.path.basename(image_path)\n",
    "        img = results[0].orig_img\n",
    "        img_height, img_width = img.shape[:2]\n",
    "\n",
    "        # Save the image to the appropriate split folder (train/val)\n",
    "        output_image_path = f\"{base_path}/images/{split}/{img_name}\"\n",
    "        os.rename(image_path, output_image_path)\n",
    "\n",
    "        # Step 7: Filter results to only include \"fish\" category (class_id = 2)\n",
    "        fish_class_index = 2  # Assuming fish is class 2 in the large model\n",
    "        for result in results:\n",
    "            for i, cls in enumerate(result.boxes.cls):\n",
    "                if cls == fish_class_index:  # Only keep fish detections\n",
    "                    bbox = result.boxes.xyxy[i].cpu().numpy()  # Bounding box (x1, y1, x2, y2)\n",
    "                    print(f\"Detected fish with bounding box: {bbox}\")\n",
    "                    print(f\"Image dimensions: {img_width}x{img_height}\")\n",
    "\n",
    "                    # Step 8: Save label file in YOLO format\n",
    "                    label_name = img_name.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "                    label_path = f\"{base_path}/labels/{split}/{label_name}\"\n",
    "\n",
    "                    # Save the bounding box in YOLO format (class_id = 0 for fish)\n",
    "                    save_yolo_labels(label_path, class_id=0, bbox=bbox, image_width=img_width, image_height=img_height)\n",
    "\n",
    "# Step 9: Process all training and validation images\n",
    "print(\"Processing all training images...\")\n",
    "process_images(train_images, \"train\")\n",
    "\n",
    "print(\"Processing all validation images...\")\n",
    "process_images(val_images, \"val\")\n",
    "\n",
    "# Step 10: Create a YAML file for the dataset\n",
    "fish_dataset_yaml = \"\"\"\n",
    "train: /content/fish_dataset/images/train\n",
    "val: /content/fish_dataset/images/val\n",
    "\n",
    "# Number of classes\n",
    "nc: 1\n",
    "\n",
    "# Class names\n",
    "names: ['fish']\n",
    "\"\"\"\n",
    "\n",
    "# Save the YAML file\n",
    "with open(\"/content/fish_dataset.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(fish_dataset_yaml)\n",
    "\n",
    "print(\"YAML file created: /content/fish_dataset.yaml\")\n",
    "\n",
    "# Step 11: Train the YOLOv8n model using the generated dataset\n",
    "small_model = YOLO(\"yolov8n.pt\")  # Load the smaller YOLOv8n model\n",
    "\n",
    "# Train the model using the generated fish-only dataset\n",
    "small_model.train(data=\"/content/fish_dataset.yaml\", epochs=50, imgsz=416, batch=16, lr0=0.001)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "# model save\n",
    "small_model.save(\"/content/yolov8n_fish_trained.pt\")\n",
    "# model val stats\n",
    "metrics = small_model.val(data=\"/content/fish_dataset.yaml\")  # This will evaluate precision, recall, and mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FR-Y3oydaYZt"
   },
   "source": [
    "### Start Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_IBNFv7m__YG",
    "outputId": "a3ad4496-d3d3-43ac-e94a-e4d45e1c9970"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_IBNFv7m__YG",
    "outputId": "a3ad4496-d3d3-43ac-e94a-e4d45e1c9970"
   },
   "outputs": [],
   "source": [
    "metrics = small_model.val(data=\"/content/fish_dataset.yaml\")  # This will evaluate precision, recall, and mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YesCg-LraWJe"
   },
   "source": [
    "### Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "sebYA_T6GeCg",
    "outputId": "97da548c-131a-4224-e0f5-218f6335e208"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# 1. Save and Download the Trained YOLOv8n Model\n",
    "small_model_path = '/content/yolov8n_fish_trained.pt'\n",
    "small_model.save(small_model_path)  # Save the trained model\n",
    "files.download(small_model_path)  # Download the trained model\n",
    "\n",
    "# 2. Zip and Download the Training Logs (runs folder)\n",
    "# YOLOv8 stores training results and logs in the 'runs' folder, which may contain weights, metrics, and other logs\n",
    "runs_folder = '/content/runs'\n",
    "runs_zip = '/content/runs.zip'\n",
    "\n",
    "# Zip the 'runs' folder if it exists\n",
    "if os.path.exists(runs_folder):\n",
    "    shutil.make_archive(runs_zip.replace('.zip', ''), 'zip', runs_folder)\n",
    "    files.download(runs_zip)  # Download the zipped 'runs' folder\n",
    "\n",
    "# 3. Zip and Download the fish_dataset Folder\n",
    "fish_dataset_folder = '/content/fish_dataset'\n",
    "fish_dataset_zip = '/content/fish_dataset.zip'\n",
    "\n",
    "# Zip the 'fish_dataset' folder\n",
    "shutil.make_archive(fish_dataset_zip.replace('.zip', ''), 'zip', fish_dataset_folder)\n",
    "files.download(fish_dataset_zip)  # Download the zipped 'fish_dataset' folder\n",
    "\n",
    "# 4. Download the Custom fish_dataset.yaml File\n",
    "yaml_file_path = '/content/fish_dataset.yaml'\n",
    "files.download(yaml_file_path)  # Download the dataset YAML file\n",
    "\n",
    "print(\"All relevant files and folders have been zipped and are ready for download!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFcGFuT0ZxhG"
   },
   "source": [
    "## Test Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhG-erbv9Biz",
    "outputId": "5811fdc4-2303-4e70-8248-c54c5db44d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing a small sample of training images to test label generation...\n",
      "\n",
      "image 1/1 /content/original/original/01649.jpg: 512x640 1 Fish, 69.2ms\n",
      "Speed: 3.2ms preprocess, 69.2ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processing /content/original/original/01649.jpg, found 1 instances.\n",
      "Detected fish with bounding box: [     175.25      150.98      378.53      304.93]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/01649.txt: 0 0.286039967182254 0.31312393356155566 0.21000108640056012 0.21146348806527945\n",
      "\n",
      "image 1/1 /content/original/original/00381.jpg: 512x640 2 Fishs, 43.9ms\n",
      "Speed: 2.2ms preprocess, 43.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processing /content/original/original/00381.jpg, found 2 instances.\n",
      "Detected fish with bounding box: [      103.2      167.75      311.31      326.53]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/00381.txt: 0 0.21410467604960293 0.3394819825560182 0.21499066313436208 0.21810340881347656\n",
      "Detected fish with bounding box: [     264.21      287.18      347.54      375.26]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/00381.txt: 0 0.31598625498369703 0.45497626000708274 0.08607530199791774 0.12098710615556318\n",
      "\n",
      "image 1/1 /content/original/original/00490.jpg: 512x640 2 Fishs, 44.0ms\n",
      "Speed: 2.2ms preprocess, 44.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processing /content/original/original/00490.jpg, found 2 instances.\n",
      "Detected fish with bounding box: [      189.4      127.22      397.04      269.02]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/00490.txt: 0 0.30290877917581355 0.27214314387394833 0.21450468331329092 0.19479051527086194\n",
      "Detected fish with bounding box: [    0.60938           0      370.87      144.29]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/00490.txt: 0 0.19187875227494675 0.09909770252940418 0.38249846529369513 0.19819540505880837\n",
      "\n",
      "image 1/1 /content/original/original/00689.jpg: 512x640 1 Fish, 43.6ms\n",
      "Speed: 3.6ms preprocess, 43.6ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processing /content/original/original/00689.jpg, found 1 instances.\n",
      "Detected fish with bounding box: [     199.43      134.48      331.65      398.19]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/00689.txt: 0 0.2743160783751937 0.3658408699454842 0.13659128866905024 0.36224130483774036\n",
      "\n",
      "image 1/1 /content/original/original/01046.jpg: 512x640 2 Fishs, 42.4ms\n",
      "Speed: 2.1ms preprocess, 42.4ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Processing /content/original/original/01046.jpg, found 2 instances.\n",
      "Detected fish with bounding box: [     379.73      234.44      455.42      285.21]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/01046.txt: 0 0.4313812886387849 0.356903076171875 0.07819177296536028 0.0697359147962633\n",
      "Detected fish with bounding box: [     388.79      344.38      447.39      381.68]\n",
      "Image dimensions: 968x728\n",
      "Label saved for /content/fish_dataset/labels/train/01046.txt: 0 0.4319138645140593 0.49866741306179174 0.06054019139817923 0.051239768227378094\n",
      "Generated labels for training set: ['01046.txt', '00490.txt', '00381.txt', '00689.txt', '01649.txt']\n",
      "Test complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import py7zr\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Step 1: Install Ultralytics YOLOv8 and py7zr (if not already installed)\n",
    "#!pip install ultralytics py7zr\n",
    "\n",
    "# Define the folder path\n",
    "unzipped_folder = \"/content/original/original\"\n",
    "\n",
    "# Step 3: Check if CUDA is available and load the large model (YOLOv8x) to CUDA if possible\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the large model (YOLOv8x) that was fine-tuned for VME detection\n",
    "large_model = YOLO(\"/content/best.pt\")  # Replace with your model path\n",
    "large_model = large_model.to(device)  # Move the model to GPU (CUDA) if available\n",
    "\n",
    "# Step 4: Create folders for the new dataset (images and labels)\n",
    "base_path = \"/content/fish_dataset\"\n",
    "\n",
    "# Create directories for train/val images and labels\n",
    "os.makedirs(f\"{base_path}/images/train\", exist_ok=True)\n",
    "os.makedirs(f\"{base_path}/images/val\", exist_ok=True)\n",
    "os.makedirs(f\"{base_path}/labels/train\", exist_ok=True)\n",
    "os.makedirs(f\"{base_path}/labels/val\", exist_ok=True)\n",
    "\n",
    "# Step 5: Define the input folder containing the original images (unzipped)\n",
    "input_images_folder = unzipped_folder\n",
    "image_paths = [os.path.join(input_images_folder, img) for img in os.listdir(input_images_folder) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Split images into train and validation (80% train, 20% validation)\n",
    "train_images = image_paths[:int(0.8 * len(image_paths))]\n",
    "val_images = image_paths[int(0.8 * len(image_paths)):]\n",
    "\n",
    "# Function to save YOLO format labels (class_id x_center y_center width height)\n",
    "def save_yolo_labels(label_path, class_id, bbox, image_width, image_height):\n",
    "    if bbox is not None and len(bbox) > 0:  # Ensure there are bounding boxes\n",
    "        x_center = (bbox[0] + bbox[2]) / 2 / image_width\n",
    "        y_center = (bbox[1] + bbox[3]) / 2 / image_height\n",
    "        width = (bbox[2] - bbox[0]) / image_width\n",
    "        height = (bbox[3] - bbox[1]) / image_height\n",
    "        with open(label_path, \"a\") as f:\n",
    "            f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "        print(f\"Label saved for {label_path}: {class_id} {x_center} {y_center} {width} {height}\")\n",
    "    else:\n",
    "        print(f\"No bounding boxes found for {label_path}, skipping label.\")\n",
    "\n",
    "# Function to process images, run inference, and save results\n",
    "def process_images(image_paths, split):\n",
    "    for image_path in image_paths:\n",
    "        # Step 6: Run the large model to detect objects in the image (with GPU if available)\n",
    "        results = large_model(image_path)\n",
    "\n",
    "        # Check if any instances were detected\n",
    "        print(f\"Processing {image_path}, found {len(results[0].boxes)} instances.\")\n",
    "\n",
    "        # Extract image dimensions\n",
    "        img_name = os.path.basename(image_path)\n",
    "        img = results[0].orig_img\n",
    "        img_height, img_width = img.shape[:2]\n",
    "\n",
    "        # Save the image to the appropriate split folder (train/val)\n",
    "        output_image_path = f\"{base_path}/images/{split}/{img_name}\"\n",
    "        os.rename(image_path, output_image_path)\n",
    "\n",
    "        # Step 7: Filter results to only include \"fish\" category (class 2 based on your provided example)\n",
    "        fish_class_index = 2  # Update to class 2 for fish\n",
    "        for result in results:\n",
    "            for i, cls in enumerate(result.boxes.cls):\n",
    "                if cls == fish_class_index:  # Only keep fish detections\n",
    "                    bbox = result.boxes.xyxy[i].cpu().numpy()  # Bounding box (x1, y1, x2, y2)\n",
    "                    print(f\"Detected fish with bounding box: {bbox}\")\n",
    "                    print(f\"Image dimensions: {img_width}x{img_height}\")\n",
    "\n",
    "                    # Step 8: Save label file in YOLO format\n",
    "                    label_name = img_name.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "                    label_path = f\"{base_path}/labels/{split}/{label_name}\"\n",
    "\n",
    "                    # Save the bounding box in YOLO format (class_id = 0 for fish)\n",
    "                    save_yolo_labels(label_path, class_id=0, bbox=bbox, image_width=img_width, image_height=img_height)\n",
    "\n",
    "# Step 9: Process train and validation images (use a small sample for testing)\n",
    "print(\"Processing a small sample of training images to test label generation...\")\n",
    "sample_images = train_images[:5]  # Test with a few images first\n",
    "process_images(sample_images, \"train\")\n",
    "\n",
    "# Check if labels were generated\n",
    "train_labels = os.listdir(f\"{base_path}/labels/train\")\n",
    "print(f\"Generated labels for training set: {train_labels}\")\n",
    "\n",
    "print(\"Test complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FR-Y3oydaYZt",
    "YesCg-LraWJe",
    "NFcGFuT0ZxhG"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
